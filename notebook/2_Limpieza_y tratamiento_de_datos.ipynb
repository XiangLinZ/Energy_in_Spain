{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Importar el soporte biblioteca\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import src.biblioteca as bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos de demanda desde un archivo CSV\n",
    "df = pd.read_csv(\"../data/scrap/demanda.csv\")\n",
    "\n",
    "# Convertir la columna \"datetime\" a formato de fecha y hora con zona horaria UTC\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], utc = True, format = \"%Y-%m-%d %H:%M:%S%z\")\n",
    "\n",
    "# Convertir la zona horaria de la columna \"datetime\" a \"Europe/Paris\"\n",
    "df[\"datetime\"] = df[\"datetime\"].dt.tz_convert(\"Europe/Paris\")\n",
    "\n",
    "# Renombrar las columnas del DataFrame para mayor claridad\n",
    "df.rename(columns = {\"value\": \"Demanda en MW\", \"datetime\": \"Fecha\"}, inplace = True)\n",
    "\n",
    "# Guardar el DataFrame como un archivo pickle para visualización posterior\n",
    "with open(f\"../data/visualizacion/px_demanda.pkl\", \"wb\") as demanda:\n",
    "    pickle.dump(df, demanda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos de demanda en tiempo real desde un archivo CSV\n",
    "df2 = pd.read_csv(\"../data/scrap/demanda_tiempo_real.csv\")\n",
    "\n",
    "# Eliminar columnas innecesarias del DataFrame\n",
    "df2.drop([\"percentage_Demanda real\", \"percentage_Demanda programada\", \"percentage_Demanda prevista\"], axis = 1, inplace = True)\n",
    "\n",
    "# Convertir la columna \"datetime\" a formato de fecha y hora con zona horaria UTC\n",
    "df2[\"datetime\"] = pd.to_datetime(df2[\"datetime\"], utc = True, format = \"%Y-%m-%d %H:%M:%S%z\")\n",
    "\n",
    "# Convertir la zona horaria de la columna \"datetime\" a \"Europe/Paris\"\n",
    "df2[\"datetime\"] = df2[\"datetime\"].dt.tz_convert(\"Europe/Paris\")\n",
    "\n",
    "# Renombrar las columnas del DataFrame para mayor claridad\n",
    "df2.rename(columns = {\"value_Demanda real\": \"Demanda real en MW\", \"value_Demanda programada\": \"Demanda programada en MW\",\n",
    "                    \"value_Demanda prevista\": \"Demanda prevista en MW\", \"datetime\": \"Fecha\"}, inplace = True)\n",
    "\n",
    "# Guardar el DataFrame como un archivo pickle para visualización posterior  \n",
    "with open(f\"../data/visualizacion/px_demanda_real.pkl\", \"wb\") as demanda_real:\n",
    "    pickle.dump(df2, demanda_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos de demanda en tiempo real desde un archivo CSV\n",
    "df3 = pd.read_csv(\"../data/scrap/demanda_tiempo_real.csv\")\n",
    "\n",
    "# Eliminar columnas innecesarias del DataFrame\n",
    "df3.drop([\"percentage_Demanda real\", \"percentage_Demanda programada\", \"percentage_Demanda prevista\"], axis = 1, inplace = True)\n",
    "\n",
    "# Convertir la columna \"datetime\" a formato de fecha y hora con zona horaria UTC\n",
    "df3[\"datetime\"] = pd.to_datetime(df3[\"datetime\"], utc = True, format = \"%Y-%m-%d %H:%M:%S%z\")\n",
    "\n",
    "# Crear una nueva columna \"drop\" que contiene \"drop\" para filas cuya columna \"datetime\" no cumple la condición de que su minuto sea divisible por 10, de lo contrario, contiene \"datetime\"\n",
    "df3[\"drop\"] = df3[\"datetime\"].where(df3[\"datetime\"].dt.minute % 10 == 0, other = \"drop\")\n",
    "\n",
    "# Eliminar las filas cuya columna \"drop\" tiene el valor \"drop\"\n",
    "df3 = df3[df3[\"drop\"] != \"drop\"]\n",
    "\n",
    "# Eliminar la columna \"drop\" del DataFrame\n",
    "df3.drop([\"drop\"], inplace = True, axis = 1)\n",
    "\n",
    "# Crear un nuevo DataFrame vacío para almacenar los datos de demanda por estaciones\n",
    "df_estaciones = pd.DataFrame()\n",
    "\n",
    "# Iterar sobre las estaciones y sus valores del diccionario \"bb.estaciones\"\n",
    "for k, v in bb.estaciones.items():\n",
    "\n",
    "    # Crear un nuevo DataFrame para almacenar los datos de la estación en un año determinado\n",
    "    estacion_todo = pd.DataFrame()\n",
    "\n",
    "    # Iterar sobre los años desde 2013 hasta 2023\n",
    "    for year in range(2013, 2024):\n",
    "\n",
    "        # Crear las fechas de inicio y fin basadas en los valores de la estación y el año actual\n",
    "        inicio = pd.to_datetime(f\"{year}-{v[0]} 00:00:00+01:00\")\n",
    "\n",
    "        if k == \"Invierno\":\n",
    "            fin = pd.to_datetime(f\"{year + 1}-{v[1]} 23:59:59+02:00\")\n",
    "\n",
    "        else:\n",
    "            fin = pd.to_datetime(f\"{year}-{v[1]} 23:59:59+02:00\")\n",
    "\n",
    "        # Filtrar los datos de demanda en tiempo real para el rango de fechas actual\n",
    "        df_estacion_año = df3[(df3[\"datetime\"] >= inicio) & (df3[\"datetime\"] <= fin)]\n",
    "\n",
    "        # Concatenar los datos filtrados al DataFrame de la estación para el año actual\n",
    "        estacion_todo = pd.concat([estacion_todo, df_estacion_año], axis = 0)\n",
    "\n",
    "    # Crear columnas de día de la semana, hora y minuto en el DataFrame de la estación\n",
    "    estacion_todo[\"dia\"] = estacion_todo[\"datetime\"].dt.day_of_week\n",
    "    estacion_todo[\"hour\"] = estacion_todo[\"datetime\"].dt.hour\n",
    "    estacion_todo[\"minute\"] = estacion_todo[\"datetime\"].dt.minute\n",
    "\n",
    "    # Calcular la demanda promedio por día de la semana, hora y minuto para la estación actual\n",
    "    estacion_semana = estacion_todo.groupby(by = [\"dia\", \"hour\", \"minute\"])[\"value_Demanda real\"].mean().reset_index()\n",
    "\n",
    "    # Crear un nuevo DataFrame con los valores de demanda promedio para la estación actual\n",
    "    estacion = pd.DataFrame(estacion_semana[\"value_Demanda real\"])\n",
    "\n",
    "    # Renombrar la columna de demanda con el nombre de la estación\n",
    "    estacion.columns = [f\"Demanda {k}\"]\n",
    "\n",
    "    # Concatenar los datos de demanda de la estación actual al DataFrame de todas las estaciones\n",
    "    df_estaciones = pd.concat([df_estaciones, estacion], axis = 1, ignore_index = True)\n",
    "\n",
    "# Renombrar las columnas del DataFrame para mayor claridad\n",
    "df_estaciones.columns = [\"Primavera\", \"Verano\", \"Otoño\", \"Invierno\"]\n",
    "\n",
    "# Se crea una nueva columna en el DataFrame de demanda por estación llamada \"Día\" que contiene el número de día en orden ascendente\n",
    "df_estaciones[\"Día\"] = [n+1 for n in range(df_estaciones.shape[0])]\n",
    "\n",
    "# Guardar el DataFrame como un archivo pickle para visualización posterior  \n",
    "with open(f\"../data/visualizacion/px_demanda_estacion.pkl\", \"wb\") as demanda_estacion:\n",
    "    pickle.dump(df_estaciones, demanda_estacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el archivo CSV de precios de mercado\n",
    "df4 = pd.read_csv(\"../data/scrap/precios_mercados.csv\")\n",
    "\n",
    "# Convierte la columna \"datetime\" a formato de fecha y hora con zona horaria UTC\n",
    "df4[\"datetime\"] = pd.to_datetime(df4[\"datetime\"], utc = True, format = \"%Y-%m-%d %H:%M:%S%z\")\n",
    "\n",
    "# Convierte la zona horaria de la columna \"datetime\" a \"Europe/Paris\"\n",
    "df4[\"datetime\"] = df4[\"datetime\"].dt.tz_convert(\"Europe/Paris\")\n",
    "\n",
    "# Crea una copia del DataFrame original\n",
    "df_diario = df4.copy()\n",
    "\n",
    "# Renombra las columnas del DataFrame copiado\n",
    "df_diario.rename(columns = {\"value\": \"Precio mayorista en €/MWh\", \"datetime\": \"Fecha\"}, inplace = True)\n",
    "\n",
    "# Guarda el DataFrame copiado en un archivo pickle\n",
    "with open(f\"../data/visualizacion/px_precio_diario.pkl\", \"wb\") as precios_diario:\n",
    "    pickle.dump(df_diario, precios_diario)\n",
    "\n",
    "# Crea una nueva columna con el mes y año en formato \"mm-YYYY\"\n",
    "df4[\"mes_y_año\"] = df4[\"datetime\"].dt.strftime(\"%m-%Y\")\n",
    "\n",
    "# Agrega por la columna \"mes_y_año\" y suma la columna \"value\"\n",
    "df_mes = (df4.groupby(by = \"mes_y_año\")[\"value\"].sum()).reset_index()\n",
    "\n",
    "# Convierte la columna \"mes_y_año\" a formato de fecha\n",
    "df_mes[\"mes_y_año\"] = pd.to_datetime(df_mes[\"mes_y_año\"], format = \"%m-%Y\")\n",
    "\n",
    "# Ordena el DataFrame por la columna \"mes_y_año\" en orden ascendente\n",
    "df_mes.sort_values(by = \"mes_y_año\", ascending = True, inplace = True)\n",
    "\n",
    "# Renombra las columnas del DataFrame de agregación\n",
    "df_mes.rename(columns = {\"value\": \"Precio mayorista en €/MWh\", \"mes_y_año\": \"Fecha\"}, inplace = True)\n",
    "\n",
    "# Guarda el DataFrame de agregación en un archivo pickle\n",
    "with open(f\"../data/visualizacion/px_precio_historico.pkl\", \"wb\") as precios_historico:\n",
    "    pickle.dump(df_mes, precios_historico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer archivo CSV\n",
    "df5 = pd.read_csv(\"../data/scrap/balance.csv\")\n",
    "\n",
    "# Convertir columna \"datetime\" a tipo de dato datetime con zona horaria en UTC\n",
    "df5[\"datetime\"] = pd.to_datetime(df5[\"datetime\"], utc = True, format = \"%Y-%m-%d %H:%M:%S%z\")\n",
    "\n",
    "# Convertir zona horaria a Europa/Paris\n",
    "df5[\"datetime\"] = df5[\"datetime\"].dt.tz_convert(\"Europe/Paris\")\n",
    "\n",
    "# Extraer el año de la columna \"datetime\"\n",
    "df5[\"año\"] = df5[\"datetime\"].dt.year\n",
    "\n",
    "# Crear nuevo DataFrame con las columnas \"datetime\", \"value_Generación no renovable\" y \"value_Generación renovable\"\n",
    "df_generado = df5[[\"datetime\", \"value_Generación no renovable\", \"value_Generación renovable\"]]\n",
    "\n",
    "# Calcular la generación total en MW sumando la generación no renovable y renovable\n",
    "df_generado[\"Generación en MW\"] = df_generado[\"value_Generación no renovable\"] + df_generado[\"value_Generación renovable\"]\n",
    "\n",
    "# Crear una columna \"mes_y_año\" en formato MM-YYYY\n",
    "df_generado[\"mes_y_año\"] = df_generado[\"datetime\"].dt.strftime(\"%m-%Y\")\n",
    "\n",
    "# Calcular el promedio mensual de la generación total en MW\n",
    "df_generado_mes = (df_generado.groupby(by = \"mes_y_año\")[\"Generación en MW\"].mean()).reset_index()\n",
    "\n",
    "# Convertir la columna \"mes_y_año\" a tipo de dato datetime en formato MM-YYYY\n",
    "df_generado_mes[\"mes_y_año\"] = pd.to_datetime(df_generado_mes[\"mes_y_año\"], format=\"%m-%Y\")\n",
    "\n",
    "# Ordenar por fecha en orden ascendente\n",
    "df_generado_mes.sort_values(by = \"mes_y_año\", ascending = True, inplace = True)\n",
    "\n",
    "# Renombrar columna \"mes_y_año\" a \"Fecha\"\n",
    "df_generado_mes.rename(columns = {\"mes_y_año\": \"Fecha\"}, inplace = True)\n",
    "\n",
    "# Guardar DataFrame en un archivo pickle\n",
    "with open(f\"../data/visualizacion/px_generado.pkl\", \"wb\") as generado:\n",
    "    pickle.dump(df_generado_mes, generado)\n",
    "\n",
    "# Calcula el balance de generación de energía no renovable\n",
    "balance_no_reno = df5[[\"percentage_Nuclear\", \"percentage_Ciclo combinado\", \"percentage_Carbón\", \"percentage_Turbina de gas\", \"percentage_Motores diésel\", \"percentage_Turbina de vapor\", \"percentage_Fuel + Gas\", \"percentage_Cogeneración\",\"percentage_Residuos no renovables\"]] * 60.25\n",
    "balance_no_reno.columns = [energia.replace(\"percentage_\", \"\") for energia in balance_no_reno.columns]\n",
    "\n",
    "# Calcula el promedio de generación de energía no renovable por tipo de tecnología\n",
    "no_renovables = balance_no_reno.fillna(0).mean().reset_index(name = \"value\").rename(columns = {\"index\": \"Energia\"})\n",
    "no_renovables[\"Tipo\"] = \"No Renovable\"\n",
    "\n",
    "# Calcula el balance de generación de energía renovable\n",
    "balance_reno = df5[[\"percentage_Turbinación bombeo\", \"percentage_Hidráulica\", \"percentage_Eólica\", \"percentage_Solar fotovoltaica\", \"percentage_Solar térmica\", \"percentage_Otras renovables\", \"percentage_Residuos renovables\", \"percentage_Hidroeólica\"]] * 39.75\n",
    "balance_reno.columns = [energia.replace(\"percentage_\", \"\") for energia in balance_reno.columns]\n",
    "\n",
    "# Calcula el promedio de generación de energía renovable por tipo de tecnología\n",
    "renovables = balance_reno.fillna(0).mean().reset_index(name = \"value\").rename(columns = {\"index\": \"Energia\"})\n",
    "renovables[\"Tipo\"] = \"Renovable\"\n",
    "\n",
    "# Concatena los DataFrames de renovables y no renovables\n",
    "energias = pd.concat([renovables, no_renovables], axis = 0)\n",
    "energias[\"value\"] = round(energias[\"value\"], 2)\n",
    "energias.sort_values(by = \"value\", ascending=False, inplace = True)\n",
    "energias.rename(columns = {\"value\": \"Porcentaje\"}, inplace = True)\n",
    "\n",
    "# Guarda el DataFrame en un archivo pickle\n",
    "with open(f\"../data/visualizacion/px_porcentage_renovables.pkl\", \"wb\") as porcentage_renovables:\n",
    "    pickle.dump(energias, porcentage_renovables)\n",
    "\n",
    "# Seleccionar las columnas de interés del DataFrame df5\n",
    "todas_energias = df5[[\"datetime\",\"value_Turbinación bombeo\",\"value_Nuclear\", \"value_Ciclo combinado\", \"value_Carbón\", \"value_Turbina de gas\", \"value_Motores diésel\", \"value_Turbina de vapor\", \"value_Fuel + Gas\", \"value_Cogeneración\",\"value_Residuos no renovables\", \"value_Hidráulica\",\"value_Eólica\", \"value_Solar fotovoltaica\", \"value_Solar térmica\", \"value_Otras renovables\", \"value_Residuos renovables\", \"value_Hidroeólica\"]]\n",
    "\n",
    "# Renombrar las columnas para quitar el prefijo \"value_\"\n",
    "todas_energias.columns = [\"datetime\"] + [energia.replace(\"value_\", \"\") for energia in todas_energias.drop(\"datetime\", axis = 1).columns]\n",
    "\n",
    "# Rellenar los valores nulos con cero\n",
    "todas_energias.fillna(0, inplace = True)\n",
    "\n",
    "# Crear una nueva columna con el formato de mes y año\n",
    "todas_energias[\"mes_y_año\"] = todas_energias[\"datetime\"].dt.strftime(\"%m-%Y\")\n",
    "\n",
    "# Agrupar los datos por mes y año, y calcular el promedio de las columnas de energía\n",
    "todas_energias_mes = todas_energias.groupby(by = \"mes_y_año\")[bb.tipos_energia].mean().reset_index()\n",
    "\n",
    "# Convertir la columna de mes y año a formato datetime\n",
    "todas_energias_mes[\"mes_y_año\"] = pd.to_datetime(todas_energias_mes[\"mes_y_año\"], format = \"%m-%Y\")\n",
    "\n",
    "# Ordenar los datos por fecha en orden ascendente\n",
    "todas_energias_mes.sort_values(by = \"mes_y_año\", ascending = True, inplace = True)\n",
    "\n",
    "# Renombrar la columna de mes y año a \"Fecha\"\n",
    "todas_energias_mes.rename(columns = {\"mes_y_año\": \"Fecha\"}, inplace = True)\n",
    "\n",
    "# Guardar los resultados en un archivo pickle\n",
    "with open(f\"../data/visualizacion/px_balance_renovables.pkl\", \"wb\") as balance_renovables:\n",
    "    pickle.dump(todas_energias_mes, balance_renovables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo CSV en un DataFrame df6\n",
    "df6 = pd.read_csv(\"../data/scrap/evolucion_renovable_no_renovable.csv\")\n",
    "\n",
    "# Convertir la columna \"datetime\" a formato datetime con información de zona horaria en UTC\n",
    "df6[\"datetime\"] = pd.to_datetime(df6[\"datetime\"], utc = True, format = \"%Y-%m-%d %H:%M:%S%z\")\n",
    "\n",
    "# Convertir la zona horaria de la columna \"datetime\" a \"Europe/Paris\"\n",
    "df6[\"datetime\"] = df6[\"datetime\"].dt.tz_convert(\"Europe/Paris\")\n",
    "\n",
    "# Calcular el promedio del porcentaje de energía renovable y no renovable\n",
    "porcentaje_reno = round(df6[\"percentage_Renovable\"].mean() * 100, 2)\n",
    "porcentaje_no_reno = round(df6[\"percentage_No renovable\"].mean() * 100, 2)\n",
    "\n",
    "# Crear una nueva columna con el formato de mes y año\n",
    "df6[\"mes_y_año\"] = df6[\"datetime\"].dt.strftime(\"%m-%Y\")\n",
    "\n",
    "# Agrupar los datos por mes y año, y calcular el promedio de los porcentajes de energía renovable y no renovable\n",
    "evolucion_reno_mes = df6.groupby(by=\"mes_y_año\")[\"percentage_Renovable\", \"percentage_No renovable\"].mean().reset_index()\n",
    "\n",
    "# Convertir la columna de mes y año a formato datetime\n",
    "evolucion_reno_mes[\"mes_y_año\"] = pd.to_datetime(evolucion_reno_mes[\"mes_y_año\"], format = \"%m-%Y\")\n",
    "\n",
    "# Ordenar los datos por fecha en orden ascendente\n",
    "evolucion_reno_mes.sort_values(by = \"mes_y_año\", ascending = True, inplace = True)\n",
    "\n",
    "# Guardar los resultados en un archivo pickle\n",
    "with open(f\"../data/visualizacion/px_evo_reno.pkl\", \"wb\") as evo_reno:\n",
    "    pickle.dump(evolucion_reno_mes, evo_reno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo CSV en un DataFrame df7\n",
    "df7 = pd.read_csv(\"../data/scrap/emisiones_CO2.csv\")\n",
    "\n",
    "# Convertir la columna \"datetime\" a formato datetime con información de zona horaria en UTC\n",
    "df7[\"datetime\"] = pd.to_datetime(df7[\"datetime\"], utc = True, format = \"%Y-%m-%d %H:%M:%S%z\")\n",
    "\n",
    "# Convertir la zona horaria de la columna \"datetime\" a \"Europe/Paris\"\n",
    "df7[\"datetime\"] = df7[\"datetime\"].dt.tz_convert(\"Europe/Paris\")\n",
    "\n",
    "# Crear una nueva columna con el formato de mes y año\n",
    "df7[\"mes_y_año\"] = df7[\"datetime\"].dt.strftime(\"%m-%Y\")\n",
    "\n",
    "# Agrupar los datos por mes y año, y sumar los valores de las columnas de emisiones de CO2\n",
    "df_mes_emisiones = df7.groupby(by=\"mes_y_año\")[\"value_Carbón\", \"value_Motores diésel\", \"value_Turbina de gas\", \"value_Turbina de vapor\", \"value_Ciclo combinado\",\n",
    "                                                \"value_Cogeneración\", \"value_Residuos no renovables\"].sum().reset_index()\n",
    "\n",
    "# Convertir la columna de mes y año a formato datetime\n",
    "df_mes_emisiones[\"mes_y_año\"] = pd.to_datetime(df_mes_emisiones[\"mes_y_año\"], format = \"%m-%Y\")\n",
    "\n",
    "# Ordenar los datos por fecha en orden ascendente\n",
    "df_mes_emisiones.sort_values(by = \"mes_y_año\", ascending = True, inplace = True)\n",
    "\n",
    "# Renombrar las columnas para hacerlas más descriptivas\n",
    "df_mes_emisiones.rename(columns = {\"mes_y_año\": \"Fecha\", \"value_Carbón\": \"Carbón\", \"value_Motores diésel\": \"Motores diésel\",\"value_Turbina de gas\": \"Turbina de gas\",\n",
    "                                    \"value_Turbina de vapor\": \"Turbina de vapor\", \"value_Ciclo combinado\": \"Ciclo combinado\", \"value_Cogeneración\": \"Cogeneración\",\n",
    "                                    \"value_Residuos no renovables\": \"Residuos no renovables\"}, inplace = True)\n",
    "\n",
    "# Guardar los resultados en un archivo pickle\n",
    "with open(f\"../data/visualizacion/px_emisiones.pkl\", \"wb\") as emisiones:\n",
    "    pickle.dump(df_mes_emisiones, emisiones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer archivo CSV y cargar datos en un DataFrame (df8)\n",
    "df8 = pd.read_csv(\"../data/scrap/perdidas_transporte.csv\")\n",
    "\n",
    "# Convertir la columna \"datetime\" en tipo datetime y ajustar a la zona horaria de Europa/París\n",
    "df8[\"datetime\"] = pd.to_datetime(df8[\"datetime\"], utc = True, format = \"%Y-%m-%d %H:%M:%S%z\")\n",
    "df8[\"datetime\"] = df8[\"datetime\"].dt.tz_convert(\"Europe/Paris\")\n",
    "\n",
    "# Multiplicar la columna \"percentage\" por 100 para convertir a porcentaje\n",
    "df8[\"percentage\"] = (df8[\"percentage\"] * 100)\n",
    "\n",
    "# Crear una nueva columna \"mes_y_año\" con el mes y año correspondiente en formato de texto\n",
    "df8[\"mes_y_año\"] = df8[\"datetime\"].dt.strftime(\"%m-%Y\")\n",
    "\n",
    "# Agrupar por mes y año, y calcular el promedio de la columna \"percentage\"\n",
    "perdidas2_mes = (df8.groupby(by = \"mes_y_año\")[\"percentage\"].mean()).reset_index()\n",
    "\n",
    "# Convertir la columna \"mes_y_año\" a tipo datetime\n",
    "perdidas2_mes[\"mes_y_año\"] =  pd.to_datetime(perdidas2_mes[\"mes_y_año\"], format = \"%m-%Y\")\n",
    "\n",
    "# Ordenar por fecha en orden ascendente\n",
    "perdidas2_mes.sort_values(by = \"mes_y_año\", ascending = True, inplace = True)\n",
    "\n",
    "# Renombrar columnas\n",
    "perdidas2_mes.rename(columns = {\"mes_y_año\" : \"Fecha\",\"percentage\": \"Porcentaje\"}, inplace = True)\n",
    "\n",
    "# Guardar el DataFrame en un archivo pickle\n",
    "with open(f\"../data/visualizacion/px_perdidas.pkl\", \"wb\") as perdidas:\n",
    "    pickle.dump(perdidas2_mes, perdidas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer archivo CSV y cargar datos en un DataFrame (df_reno_ccaa)\n",
    "df_reno_ccaa = pd.read_csv(\"../data/scrap/evolucion_renovable_no_renovable_ccaa.csv\")\n",
    "\n",
    "# Mapear los valores de la columna \"ccaa\" utilizando un diccionario del soporte biblioteca\n",
    "df_reno_ccaa[\"ccaa\"] = df_reno_ccaa[\"ccaa\"].map(bb.ccaa_real)\n",
    "\n",
    "# Guardar el DataFrame en un nuevo archivo CSV en la carpeta \"../data/visualizacion/\" \n",
    "df_reno_ccaa.to_csv(\"../data/visualizacion/reno_ccaa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
